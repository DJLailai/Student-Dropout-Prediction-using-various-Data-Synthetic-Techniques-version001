{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4802354,"sourceType":"datasetVersion","datasetId":2780494},{"sourceId":6355109,"sourceType":"datasetVersion","datasetId":3660264},{"sourceId":9090778,"sourceType":"datasetVersion","datasetId":5485714},{"sourceId":9858248,"sourceType":"datasetVersion","datasetId":5920340}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset=pd.read_csv(r\"/kaggle/input/journal-education-datasets-v000/education_data_for_all_train.csv\")\ndataset.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_state = 96","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import svm\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble import VotingClassifier\n\n\nprint(\"\\n lightgbm \\n\",\"===\"*30)\nroc_curve_data = {}\nauc_scores = {}\nalgorithms_performances_new = { }\n\nimport lightgbm\nfrom sklearn.metrics import confusion_matrix\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom imblearn.metrics import geometric_mean_score\nimport lightgbm as lgb\nimport joblib\n\n\n\n###### print(\"===========***\"*3,\" plot functions \",\"===========***\"*3)\nimport matplotlib.pyplot as plt\n\ndef plot_roc_curve(fpr_list, tpr_list, pic_name_list,label=None):\n    \n    fpr = fpr_list[0]\n    tpr = tpr_list[0]\n    \n    fpr_1 = fpr_list[1]\n    tpr_1 = tpr_list[1]\n    \n    fpr_2 = fpr_list[2]\n    tpr_2 = tpr_list[2]\n    \n    pic_name   =  \"AUC : \" + str(pic_name_list[0])\n    pic_name_1 =  \"AUC : \" + str(pic_name_list[1])\n    pic_name_2 =  \"AUC : \" + str(pic_name_list[2])\n    \n    pic_route = r\"\\kaggle\\working\\ \" + pic_name + \".png\"\n    \n    fig, ax = plt.subplots(figsize=(7,7)) \n    \n#     plt.figure(figsize=(5,5))\n    ax.plot(fpr  , tpr  , linewidth=3, color = \"cornflowerblue\", label=pic_name)\n    ax.plot(fpr_1, tpr_1, linewidth=3, color = \"darkorange\", label=pic_name_1)\n    ax.plot(fpr_2, tpr_2, linewidth=3, color = \"limegreen\", label=pic_name_2)\n    \n#     plt.plot(fpr, tpr, linewidth=2, label=pic_name)\n    \n    ax.plot([0,1],[0,1], \"r--\") \n    ax.axis([0,1,0,1])\n    ax.legend(loc=\"lower left\")\n#     ax.set_title(pic_name)\n    ax.grid(False)\n    \n    fig = ax.figure\n    fig.savefig(pic_route)\n\n    ax.set_xlabel(\"False Positive Rate\")\n    ax.set_ylabel(\"True Positive rate\")\n\n    \n    \n    \nprint(\"===========***\"*3,\" metric function \",\"===========***\"*3)\n\n\ndef performances_metrics(algorithms_performances_new, \n                         auc_avg,auc_std,\n                         acc_avg,acc_std,\n                         f1_avg,f1_std,\n                         key_words,\n                         y_test,\n                         y_pred):\n    \n    \n\n    key_words = str(key_words)\n    print (\" in the function, the key words == \",key_words )\n    print(\"std_auc\",std_auc)\n    print(\"=========\",key_words,\"====@@====\",auc_avg, \"±\" , auc_std ) #roc_auc_score(y_test, y_pred))\n\n    algorithms_performances_new[key_words] = [auc_avg] # [roc_auc_score(y_test, y_pred)]\n    \n    cm = confusion_matrix(y_test, output_y_pred(y_pred))\n \n    cm = cm.astype(np.float32)\n    FP = cm.sum(axis=0) - np.diag(cm)\n    FN = cm.sum(axis=1) - np.diag(cm)\n    TP = np.diag(cm)\n    TN = cm.sum() - (FP + FN + TP)\n    \n    TPR = TP / (TP + FN)     # Sensitivity, hit rate, recall, or true positive rate\n    TNR = TN / (TN + FP)     # Specificity or true negative rate\n    PPV = TP / (TP + FP)     # Precision or positive predictive value\n    NPV = TN / (TN + FN)     # Negative predictive value\n    FPR = FP / (FP + TN)     # Fall out or false positive rate \n    FNR = FN / (TP + FN)     # False negative rate\n    FDR = FP / (TP + FP)     # False discovery rate\n    \n    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n    \n    # accuracy    = accuracy_score(y_test, output_y_pred(y_pred))\n    precision   = precision_score(y_test, output_y_pred(y_pred))\n    recall      = recall_score(y_test, output_y_pred(y_pred))\n    # f1          = f1_score(y_test,output_y_pred(y_pred))\n    KS          = max(TPR-FPR)\n    Specificity = 1- fpr\n    G_Mean      = geometric_mean_score(y_test, output_y_pred(y_pred))\n    BAcc        = ((TPR + TNR)/2)[0]                         #balanced accuracy (BAcc)\n    tpr         = tpr\n    MCC         = (TP*TN-FP*FN)/((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**0.5\n#     precision = TP/(TP+FP)\n#     recall    = TP/(TP+FN)\n    counts_ratio    = output_y_pred(y_pred).sum()/len(y_pred)\n    Randon_accuracy = ((TP + FN)*(TP+FP) + (TN+FP)*(TN+FN))/(TP+TN+FP+FN)**2\n    kappa0          = (TP+TN)/(TP+TN+FP+FN)\n    kappa           = (kappa0-Randon_accuracy)/(1-Randon_accuracy)                                                     \n                                                         \n\n    \n    algorithms_performances_new[key_words].append(auc_std) \n    algorithms_performances_new[key_words].append(acc_avg)\n    algorithms_performances_new[key_words].append(acc_std)\n    algorithms_performances_new[key_words].append(f1_avg)\n    algorithms_performances_new[key_words].append(f1_std)\n    \n    \n    algorithms_performances_new[key_words].append(precision)\n    algorithms_performances_new[key_words].append(recall)\n    # algorithms_performances_new[key_words].append(f1)\n    algorithms_performances_new[key_words].append(KS)\n    algorithms_performances_new[key_words].append(G_Mean)\n    algorithms_performances_new[key_words].append(BAcc)\n    algorithms_performances_new[key_words].append(tpr[1])\n    algorithms_performances_new[key_words].append(MCC[1])\n    algorithms_performances_new[key_words].append(counts_ratio)\n    algorithms_performances_new[key_words].append(kappa[1])\n    \n    pd.DataFrame(algorithms_performances_new,index=[\"AUC\",\"AUC std\",\n                                                    \"Accuracy\",\"Accuracy std\",\n                                                    \"F1 score\",\"F1 score std\",\n                                                    \"Precision\",\"Recall\",\n                                                    \"KS\",\"G_Mean\",\"BAcc\",\"tpr\",\"MCC\",\"counts_ratio\",\"kappa\"\n                                                   ]).transpose()\n    return algorithms_performances_new\n\n\ndef output_y_pred(y_pred):\n    threshold = 0.5\n    y_pred[y_pred <= threshold] = 0.\n    y_pred[y_pred >  threshold] = 1.\n    return y_pred\n\n\ndef data_preprocessing(df):\n    \n    df.rename(columns={'Target':'label'},inplace = True)\n    df.rename(columns = {'Nacionality':'Nationality', 'Age at enrollment':'Age'}, inplace = True)\n    \n    return df\n\n\ndef standardize_features(df, label_column):\n    # Separate features and label\n    features = df.drop(columns=label_column)\n    label = df[label_column]\n\n    # Initialize the StandardScaler\n    scaler = StandardScaler()\n\n    # Fit and transform the features\n    features_scaled = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n\n    # Combine the scaled features with the label\n    df_scaled = pd.concat([features_scaled, label.reset_index(drop=True)], axis=1)\n\n    return df_scaled\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import svm\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install ctgan","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install sdv","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/penfever/TuneTables.git\n# !rm -rf /kaggle/working/*","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd /kaggle/working/TuneTables/tunetables","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! python batch/run_tt_job.py\n# ! python  run_baselines.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score,\\\n                            accuracy_score, balanced_accuracy_score,classification_report,confusion_matrix#,\\\n#                             plot_confusion_matrix, confusion_matrix\n\n\n# import sklearn.metrics.plot_confusion_matrix\n\n\nfrom sklearn.model_selection import KFold, GridSearchCV\n\nimport lightgbm as lgb\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, LeakyReLU\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nimport tensorflow.keras.backend as K\nfrom sklearn.utils import shuffle\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nimport tensorflow as tf\n# np.random.seed(1635848)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_for_train            = pd.read_csv(r'/kaggle/input/journal-education-datasets-v000/education_data_for_all_train.csv')\n# df_for_train = data_preprocessing(df_for_train)\n# df_for_train.drop([\"Unnamed: 0\"],axis = 1,inplace = True)\n\n\ndf_for_train            = pd.read_csv(r'/kaggle/input/journal-education-datasets-v000/education_data_for_all_train_original labels.csv')\ndf_for_train = data_preprocessing(df_for_train)\ndf_for_train.drop([\"Unnamed: 0\"],axis = 1,inplace = True)\n\n\ndf_for_test             = pd.read_csv(r'/kaggle/input/journal-education-datasets-v000/education_data_for_all_test.csv')\ndf_for_test = data_preprocessing(df_for_test)\ndf_for_test.drop([\"Unnamed: 0\"],axis = 1,inplace = True)\n\n# df_for_train_distilled  = pd.read_excel(r'/kaggle/input/journal-education-datasets-v000/distilled_for_train_TKP.xlsx')\ndf_for_train_distilled  = pd.read_excel(r'/kaggle/input/journal-education-datasets-v000/distilled_for_train.xlsx')\ndf_for_train_distilled = data_preprocessing(df_for_train_distilled)\ndf_for_train_distilled.drop([\"Unnamed: 0\"],axis = 1,inplace = True)\ndf_for_train_distilled.columns = df_for_train.columns\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndf_for_train['label'] = df_for_train['label'].map({\n                                    'Dropout':1,\n                                    'Enrolled':0,\n                                    'Graduate':0})\n\n# df_for_train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len_datashape = df_for_train.shape[0]\n# len_datashape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# df.head()\n# df = df.iloc[:-10,:]\nprint(df_for_train.shape)\n\n# df_original = data_preprocessing(df_for_train)\n\nscaler = StandardScaler()\n\n# df_original['label'] = df_original['label'].map({'Dropout':1,\n#                                                 'Enrolled':0,\n#                                                 'Graduate':0})\n# print(df_original[\"label\"].unique())\n\n# X = scaler.fit_transform(df_original.drop('label', axis = 1))\n# y = df_original['label'].values\n\n# X_train_original, X_test_original, y_train_original, y_test_original = train_test_split(X, y, test_size=0.2,\n#                                                                                         random_state = random_state)\n\n# df_train_original = np.concatenate ((X_train_original,y_train_original.reshape(-1,1)),axis=1)\n# df_test_original  = np.concatenate ((X_test_original,y_test_original.reshape(-1,1)),axis=1)\n\n\ndiscrete_columns = list(df_for_train.columns.values)\n\ndf_for_train_scaled = standardize_features(df_for_train, 'label')\ndf_for_test_scaled  = standardize_features(df_for_test, 'label')\ndf_for_train_distilled_scaled  = standardize_features(df_for_train_distilled, 'label')\n\n\nX_train_original = df_for_train_scaled.iloc[:,:-1].values   \ny_train_original = df_for_train_scaled[\"label\"].values\n\n# X_test_original  # 这是general的测试集 X_test\n# y_test_original  # 这是general的测试集 y_test\n\nX_test_original  = df_for_test_scaled.iloc[:,:-1].values\ny_test_original  = df_for_test_scaled[\"label\"].values\n\n\nX_train_distilled = df_for_train_distilled_scaled.iloc[:,:-1].values  \ny_train_distilled = df_for_train_distilled_scaled[\"label\"].values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_for_train_distilled_scaled.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_for_train_scaled.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_for_test_scaled.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_the_distilled_100.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n''' this is the distilled dataset ''' #数据蒸馏的样本数据集\n\ndf_x_distilled  = df_for_train_distilled.drop([\"label\"],axis = \"columns\")\ndf_y_distilled  = df_for_train_distilled[\"label\"]\n\n\ndf_labelled_x   = df_for_train.drop([\"label\"],axis = \"columns\")\ndf_labelled_y   = df_for_train[\"label\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_for_train_distilled.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"data synthetic process started...\")\n\n\nepochs = [10,100,500,1000,2000,3000,5000]\nepochs = [100,500,2000,len_datashape]\nepoch  = epochs[2]\nepoch  = epochs[1]\n    \n\ndef the_conditional_generated_datasets(df_for_train_scaled,epoch):\n    \n    df_train_shaped = df_for_train_scaled\n\n    import time\n\n    import sdv\n    from sdv.metadata import SingleTableMetadata\n    from sdv.single_table import GaussianCopulaSynthesizer\n    \n    from sdv.single_table import CTGANSynthesizer\n\n    '''training the conditional gannetwork'''\n    metadata = SingleTableMetadata()\n    metadata.detect_from_dataframe(df_train_shaped)\n    metadata.visualize(show_table_details='summarized',output_filepath='my_metadata.png')\n\n    '''generate the synthetic data'''\n\n\n\n    start_time = time.time()\n\n    synthesizer = CTGANSynthesizer(metadata,enforce_rounding=False,\n                                   epochs=epoch, \n                                   verbose=True)\n    \n    synthesizer.fit(df_train_shaped)\n    synthetic_data = synthesizer.sample(num_rows=1000)\n\n    end_time = time.time()\n\n    print(\"running time == \", end_time - start_time )\n\n    ''' generating the datasets'''\n    synthetic_data_dict = {}\n    sample_sizes = [100,500,1000,2000,3000]\n\n    # Create synthetic data\n    for sample_size in sample_sizes:\n        key_words = \"syn_data_set_\" + str(sample_size)\n        synthetic_data_dict[key_words] = synthesizer.sample(sample_size)\n        synthetic_data_dict[key_words].to_excel(\"/kaggle/working/stats_\"+ key_words + \"_\" + str(epoch)+ \"_.xlsx\")\n\n    ''' plot the conditional tabular generative adversal network'''\n\n    def synthetic_plot(synthesizer):\n        G_Loss = synthesizer.get_loss_values()[\"Generator Loss\"]\n        D_Loss = synthesizer.get_loss_values()[\"Discriminator Loss\"]\n        x_index = synthesizer.get_loss_values()[\"Epoch\"]\n\n        fig,ax = plt.subplots() \n        ax.plot(x_index,G_Loss,label='G_Loss')\n        ax.plot(x_index,D_Loss,label='D_Loss')\n\n        ax.set_xlabel('epochs')\n        ax.set_ylabel('L')\n\n        ax.set_title('synthetic with {} epoches'.format(epoch))\n        ax.legend()\n        plt.show()\n\n    synthetic_plot(synthesizer)\n    \n    return synthetic_data_dict\n\n# epoch = 200\nsynthetic_data_dict = the_conditional_generated_datasets(df_for_train_scaled,epoch)\n\n\n                                                         \nsynthetic_data_dict[\"syn_data_set_2000\"].rename(columns={'Target':'label'},inplace = True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"synthetic_data_dict[\"syn_data_set_2000\"].to_csv('/kaggle/working/synthetic_2000.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train_original[:5]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import libraries\nimport os\nimport pathlib\n\n# Let's say you already have list of files under /kaggle/working directory\nfor n in range(10):\n    with open(os.getcwd() + '/file_' + str(n) + '.png', 'w') as file:\n        file.write('delete this file')\n        \n# Deleting the files\nfiles_to_delete = './*.png' # this considers only \".txt\" files. If you want to delete all files, use \"./*\"\nfiles_list = pathlib.Path(os.getcwd()).glob(files_to_delete)\nfor file_path in files_list:\n    os.remove(file_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_original = pd.read_csv(r\"/kaggle/input/higher-education-predictors-of-student-retention/dataset.csv\")\n# # df.info()\n# df_original.rename(columns = {'Nacionality':'Nationality', 'Age at enrollment':'Age'}, inplace = True)\n\n# df_original.rename(columns={'Target':'label'},inplace = True)\n# df_original.label.value_counts()\n# scaler = StandardScaler()\n# df_original['label'] = df_original['label'].map({\n#                                     'Dropout':1,\n#                                     'Enrolled':0,\n#                                     'Graduate':0})\n\n\ndf_synthetic_2000 = synthetic_data_dict[\"syn_data_set_2000\"].copy()\n# df_synthetic_2000.rename(columns = {'Nacionality':'Nationality', 'Age at enrollment':'Age'}, inplace = True)\n\n# df_synthetic_2000.rename(columns={'Target':'label'},inplace = True)\n\n# scaler = StandardScaler()\n# df_synthetic_2000['label'] =df_synthetic_2000['label'].map({\n#                                         'Dropout':1,\n#                                         'Enrolled':0,\n#                                         'Graduate':0})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# dataset_dict= {}\n\n# df_labelled_x_completee_data  = df_selective_2.drop([\"Target\"],axis = \"columns\")\n# df_labelled_x_selective_data = df_selective_2[important_cols]\n\n# dataset_dict[\"df_labelled_x_completee_data\"] = df_labelled_x_completee_data\n# dataset_dict[\"df_labelled_x_selective_data\"] = df_labelled_x_selective_data\n\n# df_y = df_selective_2[\"Target\"]\n\n\n\n# sns.set(color_codes=True)\ncolor_dict = dict({'0':'orange',\n                   '1':'#067ef7'\n                   })\n\nnrows = 7\n\ndef original_data_hist_plot(dataset_dict):\n    \n    sns.set_theme(style=\"white\")\n    \n    n = len(dataset_dict)\n    \n    fig, ax = plt.subplots(nrows,int(n/nrows), sharey=\"row\",figsize=(10,10))\n\n    ck = 0\n    keys = list(dataset_dict.keys())\n    for keys_index in range(len(dataset_dict.keys())):\n        \n        X_CV =  dataset_dict[keys[keys_index]]\n        y_CV =  df_y\n    \n#         print(\"imbalanced ratio : \",len(y_give_CV)/y_give_CV.sum())\n        X_stand = StandardScaler().fit_transform(X_CV)\n        pca = PCA(n_components=2).fit(X_stand)\n        X_pca = pca.transform(X_stand)\n        \n            \n#         fig_name = \"ratio : \" + str(np.round(len(y_CV)/y_CV.sum(),1))\n\n    \n        sns.scatterplot(x=X_pca[:, 0], \n                        y=X_pca[:, 1], hue=y_CV.astype(str), alpha=0.7, ax = ax[ck//nrows,ck%nrows],\n                        edgecolor=\"white\",\n                        palette = color_dict,edgecolors=None)\n        \n        \n#         plt.xlabel('1st Principal Component')\n#         plt.ylabel('2nd Principal Component')\n        \n        ax[ck//nrows,ck%nrows].title.set_text(keys[keys_index])\n        ax[ck//nrows,ck%nrows].grid(False)\n        ax[ck//nrows,ck%nrows].set_xlim(-10, 20)\n        ax[ck//nrows,ck%nrows].set_ylim(-5, 20)\n\n        \n        ck += 1\n\n        plt.tick_params(bottom=False, labelbottom=False, labelleft=False)\n\n\n    plt.grid(False)\n    plt.suptitle('Training set visualisation using PCA features')\n    plt.savefig(\"data distribution plotting.png\",dpi=600)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Histogram\n\nselected_cols = [\"Curricular units 2nd sem (grade)\",\"Curricular units 2nd sem (approved)\",\n                \"Curricular units 1st sem (grade)\",\"Curricular units 1st sem (approved)\",\n                \"Gender\",\"Age\",\n                 \"Unemployment rate\",\"Debtor\"]\n\nck = 0\nnrows = 2\nncols = int(len(selected_cols)/nrows)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn\n\n''' this is the first one '''   #原始数据集\n\n\n# print(\"\\n原始训练集：\")\n# print(df_for_train_scaled.shape)\n# print(\"\\n原始测试集：\")\n# print(df_for_test_scaled.shape)\n\n# df_original_y = {}\n# df_original_x = X_train_original\n# df_original_y = y_train_original\n\n\n\n\noriginal_column_names = list(df_for_train.columns)\n'''============================================'''\n'''============================================'''\n\n\n''' this is the second one '''  # 2000个样本的数据集\ndf_synthetic_2000_students  = df_synthetic_2000.copy()\n\ndf_synthetic_2000_students_x  = df_synthetic_2000_students.drop([\"label\"],axis = \"columns\")\ndf_synthetic_2000_students_y  = df_synthetic_2000_students[\"label\"]\n\n'''============================================'''\n'''============================================'''\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# df_for_train_scaled.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_x_original_for_train = X_train_original\ndf_y_original_for_train = y_train_original\n\ndf_x_synthetic_for_train   = df_synthetic_2000_students.drop([\"label\"],axis = \"columns\")\ndf_y_synthetic__for_train  = df_synthetic_2000_students[\"label\"]\n\n\ndf_y = {}\n\n\nimportant_cols = [\n                   'Marital status', 'Application mode', 'Application order', 'Course',\n                   'Daytime/evening attendance', 'Previous qualification', 'Nationality',\n                   \"Mother's qualification\", \"Father's qualification\",\"Mother's occupation\", \"Father's occupation\", \n                   'Displaced',\n                   'Educational special needs', \n                   'Debtor', 'Tuition fees up to date',\n                   \n                   'Gender', 'Scholarship holder', 'Age', 'International',\n                   \n#                    'Curricular units 1st sem (credited)',\n#                    'Curricular units 1st sem (enrolled)',\n#                    'Curricular units 1st sem (evaluations)',\n#                    'Curricular units 1st sem (approved)',\n#                    'Curricular units 1st sem (grade)',\n#                    'Curricular units 1st sem (without evaluations)',\n#                    'Curricular units 2nd sem (credited)',\n#                    'Curricular units 2nd sem (enrolled)',\n#                    'Curricular units 2nd sem (evaluations)',\n#                    'Curricular units 2nd sem (approved)',\n#                    'Curricular units 2nd sem (grade)',\n#                    'Curricular units 2nd sem (without evaluations)',\n\n                   'Unemployment rate','Inflation rate', 'GDP', \n#                    'Target'\n                   ]\n\ncomplete_cols = [   \n                   # demographic\n                   'Marital status', 'Application mode', 'Application order', 'Course',\n                   'Daytime/evening attendance', 'Previous qualification', 'Nationality',\n                   \"Mother's qualification\", \"Father's qualification\",\"Mother's occupation\", \"Father's occupation\", \n                   'Displaced',\n                   'Educational special needs', \n                     \n                   # socioeconomic\n                   'Debtor', 'Tuition fees up to date','Scholarship holder', 'International', \n                   \n                   'Gender',  'Age',\n                   \n                   'Curricular units 1st sem (credited)',\n                   'Curricular units 1st sem (enrolled)',\n                   'Curricular units 1st sem (evaluations)',\n                   'Curricular units 1st sem (approved)',\n                   'Curricular units 1st sem (grade)',\n                   'Curricular units 1st sem (without evaluations)',\n                   'Curricular units 2nd sem (credited)',\n                   'Curricular units 2nd sem (enrolled)',\n                   'Curricular units 2nd sem (evaluations)',\n                   'Curricular units 2nd sem (approved)',\n                   'Curricular units 2nd sem (grade)',\n                   'Curricular units 2nd sem (without evaluations)',\n                    \n                    # macroeconomic\n                   'Unemployment rate','Inflation rate', 'GDP', \n#                    'Target'\n                   ]\n\nacademic_cols = [\n                   'Curricular units 1st sem (credited)',\n                   'Curricular units 1st sem (enrolled)',\n                   'Curricular units 1st sem (evaluations)',\n                   'Curricular units 1st sem (approved)',\n                   'Curricular units 1st sem (grade)',\n                   'Curricular units 1st sem (without evaluations)',\n                   'Curricular units 2nd sem (credited)',\n                   'Curricular units 2nd sem (enrolled)',\n                   'Curricular units 2nd sem (evaluations)',\n                   'Curricular units 2nd sem (approved)',\n                   'Curricular units 2nd sem (grade)',\n                   'Curricular units 2nd sem (without evaluations)',\n                    ]\n\n\n\nMacroeconomic_col = ['Unemployment rate',\n                     'Inflation rate',\n                     'GDP']\n\nSocioeconomic_col = ['Debtor', \n                     'Tuition fees up to date',\n                     'Scholarship holder',\n                     'International', ]\nDemographic_col   = [                   \n                       'Marital status', 'Application mode', 'Application order', 'Course',\n                       'Daytime/evening attendance', 'Previous qualification', 'Nationality',\n                       \"Mother's qualification\", \"Father's qualification\",\"Mother's occupation\", \"Father's occupation\", \n                       'Displaced',\n                       'Educational special needs', ]\n\n\ndf_x_original_complete      = df_for_train_scaled[complete_cols]\n\ndf_x_original_academic      = df_for_train_scaled[academic_cols]\n\ndf_x_original_macro_econ    = df_for_train_scaled[Macroeconomic_col]\n\ndf_x_original_Demographic   = df_for_train_scaled[Demographic_col]\n\ndf_x_original_Socioeconomic = df_for_train_scaled[Socioeconomic_col]\n\ndf_x_original_onlynot_academic = df_for_train_scaled[important_cols]\n\n\n\ndf_dataset_dict = {}\n\ndf_dataset_dict[\"complete data\"]             = df_x_original_complete\ndf_dataset_dict[\"only academic data\"]        = df_x_original_academic\ndf_dataset_dict[\"without academic data\"]     = df_x_original_onlynot_academic\ndf_dataset_dict[\" only Demographic data\"]    = df_x_original_Demographic\n\n\ndf_y[\"complete data\"]            = df_y_original_for_train\ndf_y[\"only academic data\"]       = df_y_original_for_train\ndf_y[\"without academic data\"]    = df_y_original_for_train\ndf_y[\" only Demographic data\"]   = df_y_original_for_train\n\n# df_labelled_dict[\"academic_cols\"]   =\n\nplot2 = {}\nplot2[\"complete data\"       ]     = df_x_original_complete\nplot2[\"only academic data\"   ]     = df_x_original_academic\nplot2[\"without academic data\"]      = df_x_original_onlynot_academic\n# plot2[\" only macro_econ data\"]    = df_labelled_x_macro_econ\nplot2[\" only Demographic data\"]     = df_x_original_Demographic\n# plot2[\" only Socioeconomic data\"]    = df_labelled_x_Socioeconomic\n\n\n'''→→→→→→→→→→→   ←←←←←←←←←←←←←'''\n''' this is for the generated adversal network'''\n'''→→→→→→→→→→→   ←←←←←←←←←←←←←'''\n\ndf_x_synthetic_for_train_complete      = df_x_synthetic_for_train[complete_cols]\n\ndf_x_synthetic_for_train_academic      = df_x_synthetic_for_train[academic_cols]\n\ndf_x_synthetic_for_train_macro_econ    = df_x_synthetic_for_train[Macroeconomic_col]\n\ndf_x_synthetic_for_train_Demographic   = df_x_synthetic_for_train[Demographic_col]\n\ndf_x_synthetic_for_train_Socioeconomic = df_x_synthetic_for_train[Socioeconomic_col]\n\ndf_x_synthetic_for_train_onlynot_academic      = df_x_synthetic_for_train[important_cols]\n\n\n\n\ndf_dataset_dict[\"synthetic ==> complete data\"]             = df_x_synthetic_for_train_complete\ndf_dataset_dict[\"synthetic ==> only academic data\"]        = df_x_synthetic_for_train_academic\ndf_dataset_dict[\"synthetic ==> without academic data\"]     = df_x_synthetic_for_train_onlynot_academic\ndf_dataset_dict[\"synthetic ==> only Demographic data\"]     = df_x_synthetic_for_train_Demographic\n\n\ndf_y[\"synthetic ==> complete data\"]           = df_synthetic_2000_students_y\ndf_y[\"synthetic ==> only academic data\"]      = df_synthetic_2000_students_y\ndf_y[\"synthetic ==> without academic data\"]   = df_synthetic_2000_students_y\ndf_y[\"synthetic ==> only Demographic data\"]   = df_synthetic_2000_students_y\n\n\n\n'''→→→→→→→→→→→   ←←←←←←←←←←←←←'''\n''' this is for the distilled datasets'''\n'''→→→→→→→→→→→   ←←←←←←←←←←←←←'''\n\ndf_labelled_x_distilled_complete      = df_for_train_distilled[complete_cols]\n\ndf_labelled_x_distilled_academic      = df_for_train_distilled[academic_cols]\n\ndf_labelled_x_distilled_macro_econ    = df_for_train_distilled[Macroeconomic_col]\n\ndf_labelled_x_distilled_Demographic   = df_for_train_distilled[Demographic_col]\n\ndf_labelled_x_distilled_Socioeconomic = df_for_train_distilled[Socioeconomic_col]\n\ndf_labelled_x_distilled_onlynot_academic = df_for_train_distilled[important_cols]\n\n\n\n\ndf_dataset_dict[\"distilled ==> complete data\"]             = df_labelled_x_distilled_complete\ndf_dataset_dict[\"distilled ==> only academic data\"]        = df_labelled_x_distilled_academic\ndf_dataset_dict[\"distilled ==> without academic data\"]     = df_labelled_x_distilled_onlynot_academic\ndf_dataset_dict[\"distilled ==> only Demographic data\"]     = df_labelled_x_distilled_Demographic\n\n\ndf_y[\"distilled ==> complete data\"]           = df_y_distilled\ndf_y[\"distilled ==> only academic data\"]      = df_y_distilled\ndf_y[\"distilled ==> without academic data\"]   = df_y_distilled\ndf_y[\"distilled ==> only Demographic data\"]   = df_y_distilled\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nNeural_network = make_pipeline(\n                                StandardScaler(),\n                                MLPClassifier(hidden_layer_sizes=(5,),\n                                             activation='logistic', \n                                             max_iter=10000,\n                                             learning_rate='invscaling',\n                                             random_state=0))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def original_test_dataset_transform(df_test_original,columns):\n   \n    columns = list(columns)\n    columns.append(\"label\")\n\n    # print(\"columns:\",columns)\n\n    df = df_test_original[columns]\n\n    scaler = StandardScaler()\n\n    original_test_x = scaler.fit_transform(df.drop('label', axis = 1))\n    original_test_y = df['label'].values\n\n    print(\"the trainset size == \",original_test_x.shape)\n    print(\"the testset size == \" ,original_test_y.shape)\n\n    # print(\"original_test_y is none\", df)\n    \n    return original_test_x,original_test_y\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport collections\n\nimport lightgbm\nfrom sklearn.metrics import confusion_matrix\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom imblearn.metrics import geometric_mean_score\nimport lightgbm as lgb\nimport joblib\n\nfrom sklearn.model_selection import train_test_split, cross_val_predict\n\nrandom_state_number = 92\n\n# print(\"X_train\",X_train.shape)\n# print(\"X_test\",X_test.shape)\n# print(\"y_train\",y_train.shape)\n# print(\"y_test\",y_test.shape)\n\n\nalgorithms_performances = {}\nclassifiers = {\n                \"Logisitic\"    : LogisticRegression(),\n                \"KNearest\"     : KNeighborsClassifier(),\n                \"Decision Tree\": DecisionTreeClassifier(),\n                \"Random Forest\": RandomForestClassifier(),\n                }\n\nmodel_explanation_linear = {}\ndf_shap_dict = {}\n\n\nnsplits = 5\n\ntrack_datasets = []\n# for n in [\"normal model\",\"LightGBM\",\"Smote LGBM\"]:\nfor n in [\"normal model\",\"LightGBM\",\"Smote LGBM\"]:\n    if n == \"normal model\":\n        for key, classifier in classifiers.items():\n            fpr_list = []\n            tpr_list = []\n            pic_name_list = []\n            for data_set in df_dataset_dict.keys():\n                print(data_set)\n                track_datasets.append(data_set)\n\n                from sklearn.model_selection import KFold\n                from sklearn.metrics import roc_auc_score, roc_curve\n                \n                kf = KFold(n_splits=nsplits, shuffle=True, random_state=random_state_number)\n\n                X = df_dataset_dict[data_set]   # x for train\n                y = df_y[data_set]#.to_numpy()  # y for train\n                test_columns = df_dataset_dict[data_set].keys()\n                \n                auc_scores = []\n                acc_scores = []\n                f1_scores  = [] \n\n                \n                for fold, (train_index, test_index) in enumerate(kf.split(X)):\n                    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n                    y_train, y_test = y[train_index], y[test_index]\n\n                \n                    X_test, y_test = original_test_dataset_transform(df_for_test_scaled, test_columns)\n                \n                    classifier.fit(X_train, y_train)\n                    print(f\"Fold {fold+1} train size: \", X_train.shape)\n                \n                    model_explanation_linear[key + \"_\" + str(data_set) + \"_fold_\" + str(fold+1)] = classifier\n                \n                    y_pred = classifier.predict_proba(X_test)[:, 1]\n                    fpr, tpr, thresh = roc_curve(y_test, y_pred)\n                    auc = roc_auc_score(y_test, y_pred)\n                    auc_scores.append(auc)\n                \n                    print(f\"{key} Fold {fold+1} train AUC score:\", auc)\n                    \n                    acc = accuracy_score(y_test, output_y_pred(y_pred))\n                    acc_scores.append(acc)\n\n                    f1  = f1_score(y_test,output_y_pred(y_pred))\n                    f1_scores.append(f1)\n                    \n                \n                avg_auc = np.mean(auc_scores)\n                std_auc = np.std(auc_scores)\n\n                avg_acc = np.mean(acc_scores)\n                std_acc = np.std(acc_scores)\n\n                avg_f1 = np.mean(f1_scores)\n                std_f1 = np.std(f1_scores)\n                \n                print(f\"Average AUC score across folds: {avg_auc}\")\n                print(f\"Standard deviation of AUC scores: {std_auc}\")\n\n                print(f\"Average ACC score across folds: {avg_acc}\")\n                print(f\"Standard deviation of ACC scores: {std_acc}\")\n\n                print(f\"Average F1 score across folds: {avg_f1}\")\n                print(f\"Standard deviation of F1 scores: {std_f1}\")\n                \n                key_words = key + \"_\" + data_set\n                algorithms_performances[key_words] = avg_auc\n                \n                print(\"std_auc\",std_auc)\n                performances_metrics(algorithms_performances,\n                                     avg_auc,std_auc,\n                                     avg_acc,std_acc,\n                                     avg_f1,std_f1,\n                                     key_words,\n                                     y_test, y_pred)\n                \n                pic_name = str(key_words) + \" \" + str(round(auc,3))\n                \n                pic_name_list.append(pic_name)\n                print(\"this is the pic name list \\n\", pic_name_list)\n                fpr_list.append(fpr)\n                tpr_list.append(tpr)\n\n            plot_roc_curve(fpr_list, tpr_list,pic_name_list)\n\n            #===============================================\n            dataset_smotes = 0\n            \n    elif n == \"LightGBM\":\n\n        model_explanation = {}\n        \n        learning_rate = 0.1\n        params = {'learning_rate': learning_rate,\n                  \"seed\": 25,\n                  \"num_iterations\": 20,\n                  'metric': [\"auc\",\"cross_entropy\"],\n                  \"objective\":\"binary\",\n                   'min_data_in_leaf': 3, \n                  'verbose': -1\n                   }\n        \n        \n        fpr_list = []\n        tpr_list = []\n        pic_name_list = []\n        \n        for data_set in df_dataset_dict.keys():\n            print(data_set)\n\n            kf = KFold(n_splits=nsplits, shuffle=True, random_state=random_state_number)\n            \n            X = df_dataset_dict[data_set]\n            y = df_y[data_set]#.to_numpy()\n            test_columns = df_dataset_dict[data_set].keys()\n            \n            auc_scores = []\n            acc_scores = []\n            f1_scores  = [] \n            \n            for fold, (train_index, test_index) in enumerate(kf.split(X)):\n                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n                y_train, y_test = y[train_index], y[test_index]\n\n                \n                df_for_shap = X_train.copy()\n                df_for_shap[\"label\"] = y_train.tolist()\n                df_shap_dict[data_set + \"_fold_\" + str(fold+1)] = df_for_shap\n\n                # print(\"df_for_shap ====  types ====\",df_for_shap.head())\n            \n                X_test, y_test = original_test_dataset_transform(df_for_test_scaled, test_columns)\n                \n                # df_shap = \n                \n                clf = lgb.LGBMClassifier(\n                    boosting_type='gbdt',\n                    num_leaves=50, reg_alpha=0.0, reg_lambda=1,\n                    max_depth=-1, n_estimators=100, objective='binary',\n                    subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n                    learning_rate=0.05, min_child_weight=50, random_state=2000, n_jobs=100,\n                    verbose = -1,\n                )\n            \n                clf.fit(X_train, y_train,\n                        eval_set=[(X_train, y_train)],\n                        eval_metric='auc',\n                        # verbose=-1# early_stopping_rounds=1000\n                       )\n            \n                model_explanation[data_set + \"_fold_\" + str(fold+1)] = clf\n\n\n\n            \n                \n\n            \n                y_pred = clf.predict_proba(X_test)[:, 1]\n            \n                y_demonstrate = {}\n                y_demonstrate[\"y_pred\"] = y_pred\n                y_demonstrate[\"y_test\"] = y_test\n            \n                fpr_gbc, tpr_gbc, thresh_gbc = roc_curve(y_test, y_pred)\n               \n                auc = roc_auc_score(y_test, y_pred)\n                auc_scores.append(auc)\n                \n                print(f\"Fold {fold+1} train AUC score: {auc}\")\n\n                acc = accuracy_score(y_test, output_y_pred(y_pred))\n                acc_scores.append(acc)\n\n                f1  = f1_score(y_test,output_y_pred(y_pred))\n                f1_scores.append(f1)\n\n            \n            avg_auc = np.mean(auc_scores)\n            std_auc = np.std(auc_scores)\n\n            avg_acc = np.mean(acc_scores)\n            std_acc = np.std(acc_scores)\n\n            avg_f1 = np.mean(f1_scores)\n            std_f1 = np.std(f1_scores)\n\n\n    \n            # Update algorithms_performances with the average AUC\n            # algorithms_performances[f\"LightGBM_{data_set}_avg_auc\"] = avg_auc\n            \n            print(f\"Average AUC score across folds: {avg_auc}\")\n            print(f\"Standard deviation of AUC scores: {std_auc}\")\n\n\n            key_words = \"LightGBM @@ \" + data_set\n\n            print (\"??\",key_words)\n            algorithms_performances[key_words] = avg_auc\n            \n            performances_metrics(algorithms_performances,\n                                     avg_auc,std_auc,\n                                     avg_acc,std_acc,\n                                     avg_f1,std_f1,\n                                     key_words, \n                                     y_test, y_pred)\n\n            pic_name = \"LightGBM @@ \" + \" \" +  str(round(auc,3))\n            print(\" ++++++++++++++++++++++++++++ key_words ,\", key_words)\n\n            pic_name_list.append(pic_name)\n            fpr_list.append(fpr_gbc)\n            tpr_list.append(tpr_gbc)\n\n        plot_roc_curve(fpr_list, tpr_list,pic_name_list)\n        \n    elif n == \"Smote LGBM\":\n        \n        learning_rate = 0.1\n        params = {'learning_rate': learning_rate,\n                  \"seed\": 25,\n                  \"num_iterations\": 20,\n                  'metric': [\"auc\",\"cross_entropy\"],\n                  \"objective\":\"binary\",\n                   'min_data_in_leaf': 3, \n                   }\n        \n        \n        fpr_list = []\n        tpr_list = []\n        pic_name_list = []\n        \n#         print(\"smote algorithm \\n\")      \n        from imblearn.over_sampling import SMOTE\n\n        for data_set in df_dataset_dict.keys():\n            print(data_set)\n\n            kf = KFold(n_splits=nsplits, shuffle=True, random_state=random_state_number)\n            \n            X = df_dataset_dict[data_set]\n            y = df_y[data_set]#.to_numpy()\n            test_columns = df_dataset_dict[data_set].keys()\n            \n            auc_scores = []\n            acc_scores = []\n            f1_scores  = [] \n            \n            for fold, (train_index, test_index) in enumerate(kf.split(X)):\n                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n                y_train, y_test = y[train_index], y[test_index]\n            \n                X_test, y_test = original_test_dataset_transform(df_for_test_scaled, test_columns)\n            \n                oversample = SMOTE(random_state=2)\n                X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n            \n                clf_resample = lgb.LGBMClassifier(\n                    boosting_type='gbdt',\n                    num_leaves=50, reg_alpha=0.0, reg_lambda=1,\n                    max_depth=-1, n_estimators=100, objective='binary',\n                    subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n                    learning_rate=0.05, min_child_weight=50, random_state=2000, n_jobs=100, #verbose=-1\n                )\n            \n                clf_resample.fit(X_train_res, y_train_res,\n                                 eval_set=[(X_train_res, y_train_res)],\n                                 eval_metric='auc', early_stopping_rounds=1000, \n                                 # verbose=-1\n                                )\n            \n                model_explanation[data_set + \"_smote_fold_\" + str(fold+1)] = clf_resample\n            \n                y_pred = clf_resample.predict_proba(X_test)[:, 1]\n            \n                y_demonstrate = {}\n                y_demonstrate[\"y_pred\"] = y_pred\n                y_demonstrate[\"y_test\"] = y_test\n            \n                key_words = \"Smote_LightGBM_\" + data_set + \"_fold_\" + str(fold+1)\n            \n                fpr_gbc, tpr_gbc, thresh_gbc = roc_curve(y_test, y_pred)\n                \n                auc = roc_auc_score(y_test, y_pred)\n                auc_scores.append(auc)\n\n                acc = accuracy_score(y_test, output_y_pred(y_pred))\n                acc_scores.append(acc)\n\n                f1  = f1_score(y_test,output_y_pred(y_pred))\n                f1_scores.append(f1)\n            \n                print(f\"{key_words} train AUC score: {auc}\")\n            \n            avg_auc = np.mean(auc_scores)\n            std_auc = np.std(auc_scores)\n\n            avg_acc = np.mean(acc_scores)\n            std_acc = np.std(acc_scores)\n\n            avg_f1 = np.mean(f1_scores)\n            std_f1 = np.std(f1_scores)\n            \n            print(f\"Average AUC score across folds: {avg_auc}\")\n            print(f\"Standard deviation of AUC scores: {std_auc}\")\n            \n            algorithms_performances[\"Smote_LightGBM_\" + data_set + \"_avg_auc\"] = avg_auc\n\n            performances_metrics(algorithms_performances,\n                                     avg_auc,std_auc,\n                                     avg_acc,std_acc,\n                                     avg_f1,std_f1,\n                                     key_words,\n                                     y_test, y_pred)\n\n            pic_name = \"Smote_LightGBM\" + \" \" +  str(round(avg_auc,3))\n\n            pic_name_list.append(pic_name)\n            fpr_list.append(fpr_gbc)\n            tpr_list.append(tpr_gbc)\n\n        plot_roc_curve(fpr_list, tpr_list,pic_name_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stats_plot_data_all = pd.DataFrame(algorithms_performances,index=[\"AUC\",\"AUC std\",\n                                                                  \"Accuracy\",\"Accuracy std\",\n                                                                  \"F1 Score\",\"F1 Score std\",\n                                                                  \"Precision\",\"Recall\",\n                                            \"KS\",\"G_Mean\",\"BAcc\",\"tpr\",\"MCC\",\n                                            \"counts_ratio\",\"kappa\"]).transpose()\n\nstats_plot_data_all.to_excel(\"/kaggle/working/stats_plot_data_all.xlsx\")\n# pd.set_option('display.max_rows', None) \nstats_plot_data_all","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stats_plot_data_all.to_excel(\"/kaggle/working/stats_plot_data_all.xlsx\")\n# to_csv('/kaggle/working/synthetic_2000.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# if key_words not in auc_scores.keys():\n#     auc_scores[key_words]=[auc]\n# else:\n#     auc_scores[key_words].append(auc)\n    \n# pd.DataFrame(performances_metrics(algorithms_performances_new,key_words,y_test, y_pred)).transpose()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_labelled_dict.keys()\ndf_labelled_dict = df_dataset_dict","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_rows = len(df_labelled_dict)\nprint(\"n_rows\",n_rows)\n\ndataset_name_indexes = range(len(df_labelled_dict.keys()))\nprint(\"dataset_name_indexes\",len(dataset_name_indexes))\n\nint(len(dataset_name_indexes)/n_rows)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def datasets_dict_with_support_sizes_plot(df_labelled_dict):\n    \n    \n    palette = {'0': 'orange', '1': '#067ef7'}\n    \n    n_rows = int(len(df_labelled_dict)/4)\n    \n    dataset_name_indexes = range(len(df_labelled_dict.keys()))\n                               \n    n_cols = int(len(dataset_name_indexes)/n_rows)\n                               \n    sns.set_theme(style=\"white\")\n    \n    n = len(df_labelled_dict)\n    \n    fig, ax = plt.subplots(n_rows,int(n_cols), sharey=\"row\",figsize=(10,10))\n    print(\"@@@ \",n_rows,int(n_cols))\n\n    ck = 0\n    keys = list(df_labelled_dict.keys())\n    \n    for dataset_name_index in dataset_name_indexes:\n        \n        \n        X_train = df_labelled_dict[keys[dataset_name_index]]\n        y_train =  df_y[keys[dataset_name_index]]#.to_numpy()\n     \n        X_stand_original = StandardScaler()   .fit_transform(X_train) \n        pca_original     = PCA(n_components=2).fit(X_stand_original)\n        X_pca            = pca_original       .transform(X_stand_original)\n        \n        \n        jk = dataset_name_index%n_cols\n        \n        print(\"== \",ck//n_cols,jk)\n \n        sns.scatterplot(x         = X_pca[:, 0], \n                        y         = X_pca[:, 1], \n                        hue       = y_train.astype(int).astype(str), \n                        alpha     = 0.3, \n                        ax        = ax[ck//n_cols,jk],\n                        edgecolor = \"white\",\n                        palette   = palette,\n                        edgecolors=None,\n                        sizes     = (70, 400),\n                        s         = 100)\n\n#         print(\"locations : \",[ck//n_cols,jk])\n        \n        dataset_name_key = keys[dataset_name_index]\n\n        ax[ck//n_cols,jk].title.set_text(dataset_name_key)\n        ax[ck//n_cols,jk].grid(False)\n        ax[ck // n_cols, jk].set_xlim(-15, 15)\n        ax[ck // n_cols, jk].set_ylim(-5, 15)\n        # ax[ck // n_cols, jk].set_xticks(range(-15, 16, 5))\n        ax[ck // n_cols, jk].set_yticks(range(-10, 16, 5)) # Set y-ticks for every 5 units\n\n\n        ck += 1\n\n    plt.tick_params(bottom=False, labelbottom=False, labelleft=False)\n    \n    plt.tight_layout()\n    plt.tight_layout(pad=2.0)\n    plt.grid(False)\n#     algos = str(\"algorithms == \" + algo)\n#     plt.title(algos)\n    plt.savefig(\"/kaggle/working/data distribution plotting.png\",dpi=600)\n    plt.tight_layout()\n    plt.show()\n    \ndatasets_dict_with_support_sizes_plot(df_labelled_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Obtain gain feature importance\nkeys  = list(df_labelled_dict.keys())\n\nprint(keys)\nmodel = model_explanation[keys[0]+\"_fold_1\"]\n\n# df_labelled_x = X_train_original\n\ngain_importance = model.feature_importances_\n\n# Display feature importance with feature names\nfeature_names = df_labelled_x.columns\ngain_importance_df = pd.DataFrame({'Feature': feature_names, 'Target': gain_importance})\nprint(gain_importance_df.sort_values(by='Target', ascending=False))\n\n(pd.Series(gain_importance, index=feature_names).nlargest(20).plot(kind='barh',label=\"importance\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport numpy as np\n\n# model_explanation","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_labelled_dict.keys()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nn = 0\n\nscenarios = keys[n]\nprint(\"scenarios : == \",scenarios)\nmodel = model_explanation[scenarios +\"_fold_1\"]\n\n\nprint(scenarios)\n\n#==========================================\n\nexplainer = shap.TreeExplainer(model)\n\n\nshap.initjs() \n\n\ndf_labelled_dict = df_dataset_dict\n\nshap_values = explainer.shap_values(df_labelled_dict[scenarios])\n\n\nplt.figure(figsize=(10, 6))\n\nplot_shap = shap.summary_plot(  shap_values[1], \n                                df_labelled_dict[scenarios],\n                                show=False, \n                                max_display = 20,\n#                                 max_display=df_labelled_dict[scenarios].shape[1]\n                             )\n\nplt.xlim(-2, 2)\nplt.title(scenarios, fontsize = 20)\n\n\nplt.savefig(\"/kaggle/working/global shap, complete dataset.png\",dpi=600)\nplt.show()\n\n# plt.savefig(plot_shap)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_for_train.label.unique()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_shap_dict.keys()\ndf_shap_dict[\"complete data_fold_1\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"force_plot_dict = {} \nforce_plot_dict[\"Graduate\" ] = 0\nforce_plot_dict[\"Dropout\"  ] = 4\n# force_plot_dict[\"Enrolled\" ] =2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# \"/kaggle/working/\"+ status\n\n# plt.savefig(\"/kaggle/working/global shap, without academic dataset.png\",dpi=600)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explainer.expected_value\nshap_values[0][1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n = 0\n\n#==============================\n\n# status =\"/kaggle/working/individual shap _\" + keys[n] +  \"plot2_Enrolled_.png\"\n# index = force_plot_dict[\"Enrolled\" ] \n# print ( keys[n] + \"\\n\" + \"the Enrolled student...\")\n\n# shap.force_plot(np.around(explainer.expected_value[1], decimals = 2), \n#                 np.around(shap_values[1][index,:], decimals = 2),\n#                 np.around(df_labelled_dict[keys[n]].iloc[index,:], decimals = 2),\n#                 # link=\"logit\",\n#                 text_rotation=15,  \n#                 matplotlib=True,\n#                 show=False\n#                )\n# # plt.xlim(-3, 3)\n# plt.savefig(status,dpi=600)\n# # plt.show()\n\n#==============================\n\nstatus = \"/kaggle/working/individual shap _\" + keys[n] + \"plot2_Graduate_.png\"\nindex = force_plot_dict[\"Graduate\"] \nprint ( keys[n] + \"\\n\" + \"the Graduate student...\")\nshap.force_plot(np.around(explainer.expected_value[1], decimals = 2), \n                np.around(shap_values[1][index], decimals = 2), \n                np.around(df_labelled_dict[keys[n]].iloc[index], decimals = 2),\n                matplotlib=True,show=False,\n                text_rotation=15,  \n               )\n# plt.xlim(-3, 3)\nplt.savefig(status,dpi=600)\nplt.show()\n\n\n#==============================\n\nstatus = \"/kaggle/working/individual shap _\" + keys[n] + \"plot2_Dropout_.png\"\nindex = force_plot_dict[\"Dropout\" ] \nprint ( keys[n] + \"\\n\" +\"the dropout student...\")\nshap.force_plot(np.around(explainer.expected_value[1], decimals = 2), \n                np.around(shap_values[1][index], decimals = 2), \n                np.around(df_labelled_dict[keys[n]].iloc[index], decimals = 2),\n                matplotlib=True,show=False,\n                text_rotation=15,  \n               )\n\n\n# plt.title(status, fontsize = 20,loc='left')\n# plt.xlim(-3, 3)\nplt.savefig(status,dpi=600)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nn = 2\nscenarios = keys[n]\n\nmodel = model_explanation[scenarios+\"_fold_1\"]\nprint(\"scenarios : == \",scenarios)\n\nexplainer = shap.TreeExplainer(model)\nshap.initjs() \n\nshap_values = explainer.shap_values(df_labelled_dict[scenarios])\n\n\nplt.figure(figsize=(10, 6))\n\n\nshap.summary_plot(  shap_values[1], \n                    df_labelled_dict[scenarios],\n                    show=False, \n                      max_display = 20,\n#                     max_display=df_labelled_dict[scenarios].shape[1]\n                 )\n\n\n\nplt.xlim(-2, 2)\nplt.title(scenarios, fontsize = 20)\n\nplt.title(scenarios, fontsize=20)\nplt.savefig(\"/kaggle/working/global shap, without academic dataset.png\",dpi=600)\n\n\nplt.show()\n\n\n# plt.savefig(plot_shap)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}